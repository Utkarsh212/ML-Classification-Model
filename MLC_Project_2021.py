# -*- coding: utf-8 -*-
"""IDS Project 2021

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vvJy3fzO0My_Wl_Ux5NPBhN0uhTPC95s

# Section 1 - Preparing Environment

---

## a) Loading libraries and modules
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from pandas.plotting import scatter_matrix
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from datetime import datetime 

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

# Set the warning message filter
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

"""## b) Setting up the controlling parameters and functions"""

# Set the random seed number for reproducible results
seedNum = 888

# Begin the timer for the script processing
startTimeScript = datetime.now()

# Set up the number of CPU cores available for multi-thread processing
n_jobs = -1

# Set the flag for splitting the dataset
splitPercentage = 0.25

# Set the number of folds for cross validation
n_folds = 10

# Set various default modeling parameters
scoring = 'accuracy'

"""## c) Loading dataset"""

dataset_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'
colNames = ['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','targetVar']
Xy_original = pd.read_csv(dataset_path, names=colNames, sep=',', header=None, index_col=0)

"""## d) Data Summerization"""

Xy_original.head(10)

Xy_original.info()

Xy_original.describe()

print(Xy_original.isnull().sum())
print('Total number of NaN in the dataframe: ', Xy_original.isnull().sum().sum())

Xy_original.groupby('targetVar').size()

"""## e) Splitting Data into Attribute-only and Target-only Sets"""

# Use variable totCol to hold the number of columns in the dataframe
totCol = len(Xy_original.columns)

# Set up variable totAttr for the total number of attribute columns
totAttr = totCol-1

# We create attribute-only and target-only datasets (X_original and y_original)
# for various visualization and cleaning/transformation operations

X_original = Xy_original.iloc[:,0:totAttr]
y_original = Xy_original.iloc[:,totAttr]

print("Xy_original.shape: {} X_original.shape: {} y_original.shape: {}".format(Xy_original.shape, X_original.shape, y_original.shape))

"""## f) Setting up the parameters for data visualization"""

# Set up the number of row and columns for visualization display.
dispCol = 4
dispRow = (totAttr // dispCol) + 1
    
# Set figure width to display the data visualization plots
fig_size = plt.rcParams["figure.figsize"]
fig_size[0] = dispCol*4
fig_size[1] = dispRow*4
plt.rcParams["figure.figsize"] = fig_size

"""# Section 2 - Data Visualization"""

Xy_original.groupby('targetVar').mean().plot(kind='bar',legend=False, subplots=True, layout=(dispRow,dispCol))
plt.show()

# Histograms for each attribute
X_original.hist(layout=(dispRow,dispCol))
plt.show()

# Box and Whisker plot for each attribute
X_original.plot(kind='box', subplots=True, layout=(dispRow,dispCol))
plt.show()

# Scatterplot matrix
scatter_matrix(X_original)
plt.show()

# Correlation matrix
fig = plt.figure(figsize=(16,12))
ax = fig.add_subplot(111)
correlations = X_original.corr(method='pearson')
cax = ax.matshow(correlations, vmin=-1, vmax=1)
fig.colorbar(cax)
plt.show()

"""# Section 3 - Preparing Data

Some dataset may require additional preparation activities that will best exposes the structure of the problem and the relationships between the input attributes and the output variable. Some data-prep tasks might include:

* Cleaning data by removing duplicates, marking missing values and even imputing missing values.
* Feature selection where redundant features may be removed.
* Data transforms where attributes are scaled or redistributed in order to best expose the structure of the problem later to learning algorithms.

## a) Feature Scaling and Data Pre-Processing
"""

# Apply feature scaling technique
preprocessing.scale(X_original, copy=False)

# Histograms for each attribute after scaling
X_original.hist(layout=(dispRow,dispCol))
plt.show()

"""## b) Splitting Data into Training and Test Sets"""

# Split the data further into training and test datasets
X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X_original, y_original, test_size=splitPercentage, stratify=y_original, random_state=seedNum)
print("X_train.shape: {} y_train_df.shape: {}".format(X_train_df.shape, y_train_df.shape))
print("X_test_df.shape: {} y_test_df.shape: {}".format(X_test_df.shape, y_test_df.shape))

"""## c) Display the Final Datasets for Model-Building"""

# Finalize the training and testing datasets for the modeling activities
X_train = X_train_df.to_numpy()
y_train = y_train_df.to_numpy()
X_test = X_test_df.to_numpy()
y_test = y_test_df.to_numpy()
print("X_train.shape: {} y_train.shape: {}".format(X_train.shape, y_train.shape))
print("X_test.shape: {} y_test.shape: {}".format(X_test.shape, y_test.shape))

"""# Section 4 - Model and Evaluate Algorithms

---

After the data-prep, we next work on finding a workable model by evaluating a subset of machine learning algorithms that are good at exploiting the structure of the training. The typical evaluation tasks include:

* Defining test options such as cross validation and the evaluation metric to use.
* Spot checking a suite of linear and nonlinear machine learning algorithms.
* Comparing the estimated accuracy of algorithms.

For this project, we will evaluate following algorithms:

* Linear Discriminant Analysis
* k-Nearest Neighbours
* Support Vector Machine
* Naive Bayes Classification

The random number seed is reset before each run to ensure that the evaluation of each algorithm is performed using the same data splits. It ensures the results are directly comparable.

## a) Set test options and evaluation metric
"""

# Set up Algorithms Spot-Checking Array
startTimeModule = datetime.now()
train_models = []
train_results = []
train_model_names = []
train_metrics = []
train_models.append(('LDA', LinearDiscriminantAnalysis()))
train_models.append(('KNN', KNeighborsClassifier(n_jobs=n_jobs)))
train_models.append(('SVM', SVC()))
train_models.append(('NBC', GaussianNB()))

# Generate model in turn
for name, model in train_models:
	startTimeModule = datetime.now()
	kfold = KFold(n_splits=n_folds, shuffle=True, random_state=seedNum)
	cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
	train_results.append(cv_results)
	train_model_names.append(name)
	train_metrics.append(cv_results.mean())
	print('For', name)
	print('Mean value :', cv_results.mean())
	print ('Model training time :', (datetime.now() - startTimeModule), '\n')	
print ('Average metrics ('+scoring+') from all models:',np.mean(train_metrics))
print ('Total training time for all models:',(datetime.now() - startTimeModule))

"""## b) Spot-checking baseline algorithms"""

fig = plt.figure(figsize=(9,6))
fig.suptitle('Algorithm Comparison - Spot Checking')
plt.bar(train_model_names,train_metrics,width=0.25)
plt.show()

"""## Section 5 - Measure predictions from the test dataset"""

test_model1 = SVC()
test_model1.fit(X_train, y_train)
predictions1 = test_model1.predict(X_test)
print('Accuracy Score:', accuracy_score(y_test, predictions1))
print(confusion_matrix(y_test, predictions1))
print(classification_report(y_test, predictions1, zero_division=1))